apiVersion: batch/v1
kind: Job
metadata:
  name: triton-profiling-job
  namespace: triton-profiling
  labels:
    author: grpereir
spec:
  template:
    metadata:
      labels:
        app: triton-profiling
        author: grpereir
    spec:
      containers:
      - name: profiling-container
        image: quay.io/grpereir/triton-profiling:latest
        command: ["/bin/sh", "-c", "sleep infinity"]
        resources:
          limits:
            nvidia.com/gpu: 1  # Request a single GPU
        env:
        - name: HF_HOME
          value: "/tmp/.cache/huggingface"
        - name: LOG_DIR
          value: "/log"  # Directory for TensorBoard logs
        - name: MODEL_DIR
          value: "/opt/app-root/src/granite-7b-lab"
        volumeMounts:
        - name: log-volume
          mountPath: "/log"
        - name: granite
          mountPath: /opt/app-root/src/granite-7b-lab
      restartPolicy: Never  # Run the job only once
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      volumes:
      - name: log-volume
        emptyDir: {}  # Temporary storage for logs (or configure a persistent volume claim if needed)
      - name: granite
        persistentVolumeClaim:
          claimName: granite-7b-lab-pvc
