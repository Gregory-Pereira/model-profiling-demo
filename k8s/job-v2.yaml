apiVersion: batch/v1
kind: Job
metadata:
  name: triton-profiling-job
  namespace: triton
spec:
  template:
    metadata:
      labels:
        app: triton-profiling
    spec:
      containers:
      - name: profiling-container
        image: quay.io/grpereir/triton-profiling:latest
        resources:
          limits:
            nvidia.com/gpu: 1  # Request a single GPU
        env:
        # - name: MODEL_DIR
        #   value: "/path_to_your_model_directory"  # Replace with the actual model path if needed
        - name: LOG_DIR
          value: "/log"  # Directory for TensorBoard logs
        volumeMounts:
        - name: log-volume
          mountPath: "/log"
        - name: csp-managed-disk
          mountPath: "/mnt/nsys/output"
        # # Use command override if needed, e.g., python script.py --args
        # command: ["python", "/path/to/your_script.py"]
      restartPolicy: Never  # Run the job only once
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      volumes:
      - name: log-volume
        emptyDir: {}  # Temporary storage for logs (or configure a persistent volume claim if needed)
      - name: csp-managed-disk
        persistentVolumeClaim:
          claimName: csp-managed-disk
  backoffLimit: 3
